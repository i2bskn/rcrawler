{"name":"RCrawler","tagline":"The wrapper of capybara for crawler.","body":"## Dependencies\r\n\r\n* nokogiri requires libxml2.\r\n* capybara-webkit requires qt. [capybara-webkit wiki](https://github.com/thoughtbot/capybara-webkit/wiki/Installing-Qt-and-compiling-capybara-webkit)\r\n\r\n## Installation\r\n\r\nAdd this line to your application's Gemfile:\r\n\r\n    gem 'rcrawler'\r\n\r\nAnd then execute:\r\n\r\n    $ bundle\r\n\r\nOr install it yourself as:\r\n\r\n    $ gem install rcrawler\r\n\r\n## Usage\r\n\r\n#### Crawl\r\n\r\n```ruby\r\nrequire \"rcrawler\"\r\n\r\nRCrawler.crawl do\r\n  # Some capybara dsl\r\n  visit(\"https://example.com/login\")\r\n  page.fill_in(\"name\", with: \"user\")\r\n  page.fill_in(\"password\", with: \"secret\")\r\n  page.click_button(\"send\")\r\n  page.save_screenshot(\"/tmp/example.png\")\r\n\r\n  # Screenshot shortcut\r\n  # visit(arg[0]) and page.save_screenshot(arg[1])\r\n  screenshot(\"http://example.com\", \"/tmp/example.png\")\r\n\r\n  # Nokogiri\r\n  # doc is return Nokogiri::HTML(page.html)\r\n  visit(\"http://example.com\")\r\n  doc.css(\"a.some_link\").each {|a| puts a.attr(\"href\")}\r\nend\r\n```\r\n\r\n#### Configuration\r\n\r\n```ruby\r\nRCrawler.configure do |c|\r\n  c.threads = 10 # => default is 8\r\n  c.timeout = 20 # => default is 10\r\n  c.timeout_proc = :ignore # => default is :raise\r\nend\r\n```\r\n\r\n#### Async processing\r\n\r\n```ruby\r\nRCrawler.async do\r\n  crawl do\r\n    # do something\r\n  end\r\n\r\n  crawl do\r\n    # do something\r\n  end\r\n\r\n  crawl do\r\n    # do something\r\n  end\r\nend\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}